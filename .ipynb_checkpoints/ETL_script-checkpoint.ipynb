{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lxml import etree as et\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import fnmatch\n",
    "import itertools\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "path = ('stackexchange1')\n",
    "\n",
    "folders = os.listdir(path)\n",
    "\n",
    "\"\"\"\n",
    "def rename_files(self, path):\n",
    "    removal = '.stackexchange.com'\n",
    "    for folder in folders:  \n",
    "        os.rename(os.path.join(path, folder), os.path.join(path, folder.replace(removal, ' ')))\n",
    "\"\"\"\n",
    "\n",
    "categories = []\n",
    "for a in folders:\n",
    "    categories.append(str(a))\n",
    "\n",
    "remover = lambda x: BeautifulSoup(x, 'lxml').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "posts_path = []\n",
    "for root, dirname, filenames in os.walk(path):\n",
    "    for filename in fnmatch.filter(filenames, 'Posts.*'):\n",
    "        realname = os.path.join(root, filename)\n",
    "        posts_path.append(realname)\n",
    "\n",
    "posts_category_parsed = []  \n",
    "for i in posts_path:\n",
    "    posts_category_parsed.append(et.parse(i).getroot().findall('row'))\n",
    "    \n",
    "for j in posts_category_parsed:\n",
    "    col_id = pd.Series([row.get('Id') for row in j]).rename('post_id')\n",
    "    #col_type = pd.Series([row.get('Type') for row in j]).rename('post_type')\n",
    "    col_post_type = pd.Series([row.get('PostTypeId') for row in j]).rename('post_type_id')\n",
    "\n",
    "    col_body = pd.Series([row.get('Body').encode('utf8') for row in j]).rename('body').apply(remover)\n",
    "    col_views = pd.Series([row.get('ViewCount') for row in j]).rename('views')\n",
    "    col_score = pd.Series([row.get('Score') for row in j]).rename('score')\n",
    "    col_fav = pd.Series([row.get('FavoriteCount') for row in j]).rename('fav_count')\n",
    "    \n",
    "    col_parentid = pd.Series([row.get('ParentId') for row in j]).rename('parent_id')\n",
    "    col_ownerid = pd.Series([row.get('OwnerUserId') for row in j]).rename('owner_id')\n",
    "    col_answer = pd.Series([row.get('AnswerCount') for row in j]).rename('answer_count')\n",
    "    col_comment = pd.Series([row.get('CommentCount') for row in j]).rename('comment_count')\n",
    "\n",
    "df_posts = pd.concat([col_id, col_post_type, col_body, col_views, col_score, col_fav, col_parentid, col_ownerid,\n",
    "                                col_answer, col_comment], join='outer', axis=1)\n",
    "\n",
    "posts_stop_list= []\n",
    "posts_stop_list2= []\n",
    "posts_stop_list3= []\n",
    "posts_final = []\n",
    "posts_combined = []\n",
    "posts_id_count_list = []\n",
    "\n",
    "for j in posts_category_parsed:\n",
    "    for row in j:\n",
    "       posts_id_count_list.append(row.get('Id'))\n",
    "\n",
    "for l, m in enumerate(col_post_type):\n",
    "    if m == '1':\n",
    "        posts_stop_list.append(l)\n",
    "\n",
    "index_list = df_posts.index.tolist()\n",
    "\n",
    "posts_stop_list.append(index_list[-1] + 1)  \n",
    "\n",
    "posts_stop_list2.append([y - x for x, y in zip(posts_stop_list, \n",
    "                                               posts_stop_list[1:])])\n",
    "\n",
    "for m in posts_stop_list2:\n",
    "    for o in m:\n",
    "        posts_stop_list3.append(o)\n",
    "\n",
    "for p, q in zip(categories, posts_stop_list3):\n",
    "        posts_final += [p for _ in range(q)]\n",
    "        \n",
    "for r, s in zip(posts_final, posts_id_count_list):\n",
    "    posts_combined += [r + '_' + str(s)]\n",
    "\n",
    "#df_posts['category'] = pd.Series(posts_combined).rename('category')  \n",
    "\n",
    "df_q = df_posts.groupby(['post_type_id']).get_group('1')\n",
    "df_a = df_posts.groupby(['post_type_id']).get_group('2')\n",
    "\n",
    "df_q.to_csv('df_q.csv', index = False)\n",
    "df_a.to_csv('df_a.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_path = []\n",
    "\n",
    "for root, dirname, filenames in os.walk(path):\n",
    "    for filename in fnmatch.filter(filenames, 'Users.*'):\n",
    "        realname = os.path.join(root, filename)\n",
    "        users_path.append(realname)\n",
    "\n",
    "users_category_parsed = []\n",
    "for i in users_path:\n",
    "    users_category_parsed.append(et.parse(i).getroot().findall('row'))\n",
    "\n",
    "for j in users_category_parsed:\n",
    "    col_id = pd.Series([row.get('Id') for row in j]).rename('user_id')\n",
    "    col_rep = pd.Series([row.get('Reputation') for row in j]).rename('user_rep')\n",
    "    col_name = pd.Series([row.get('DisplayName') for row in j]).rename('display_name')\n",
    "    col_views =pd.Series([row.get('Views') for row in j]).rename('view_count')\n",
    "    col_upvotes =pd.Series([row.get('UpVotes') for row in j]).rename('upvotes')\n",
    "    col_downvotes = pd.Series([row.get('DownVotes') for row in j]).rename('downvotes')\n",
    "\n",
    "df_users = pd.concat([col_id, col_rep, col_name, col_views, col_upvotes, col_downvotes], join='outer', axis=1)\n",
    "\n",
    "\n",
    "users_stop_list= []\n",
    "users_stop_list2= []\n",
    "users_stop_list3= []\n",
    "users_final = []\n",
    "users_combined = []\n",
    "users_id_count_list = []\n",
    "\n",
    "for l, m in enumerate(users_id_count_list):\n",
    "    if m == '-1':\n",
    "        users_stop_list.append(l)\n",
    "\n",
    "        index_list = df_users.index.tolist()\n",
    "\n",
    "users_stop_list.append(index_list[-1] + 1)\n",
    "\n",
    "users_stop_list2.append([y - x for x, y in zip(users_stop_list, users_stop_list[1:])])\n",
    "\n",
    "for m in users_stop_list2:\n",
    "    for o in m:\n",
    "        users_stop_list3.append(o)\n",
    "\n",
    "for p, q in zip(categories, users_stop_list3):\n",
    "    users_final += [p for _ in range(q)]\n",
    "\n",
    "for r, s in zip(users_final, users_id_count_list):\n",
    "    users_combined += [r + '_' + str(s)]\n",
    "\n",
    "#df_users['category'] = pd.Series(users_combined).rename('category')  \n",
    "\n",
    "#df_users.to_sql(name='all_users', con=engine)\n",
    "\n",
    "df_users.to_csv('df_users.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s3.Object(bucket_name='stackexchangedatatest', key='df_q.csv')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "keys = pd.read_csv('keys.csv')\n",
    "access_key = keys['Access key ID'][0]\n",
    "access_secret = keys['Secret access key'][0]\n",
    "\n",
    "bucket_name = 'stackexchangedatatest'\n",
    "file_name_a = open('df_a.csv', 'rb')\n",
    "file_name_q = open('df_q.csv', 'rb')\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                    aws_access_key_id=access_key,\n",
    "                    aws_secret_access_key=access_secret,\n",
    "                    region_name='us-east-1')\n",
    "s3.Bucket(bucket_name).put_object(Key='df_a.csv', Body=file_name_a)\n",
    "s3.Bucket(bucket_name).put_object(Key='df_q.csv', Body=file_name_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE questions (\n",
      "\tpost_id INTEGER NOT NULL, \n",
      "\tpost_type_id INTEGER, \n",
      "\tbody VARCHAR(32), \n",
      "\tviews INTEGER, \n",
      "\tscore INTEGER, \n",
      "\tfav_count INTEGER, \n",
      "\tparent_id INTEGER, \n",
      "\towner_id INTEGER, \n",
      "\tanswer_count INTEGER, \n",
      "\tcomment_count INTEGER, \n",
      "\tPRIMARY KEY (post_id)\n",
      ")\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sqlalchemy_redshift.commands.CopyCommand object at 0x000002554B927B70>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg2\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy.schema import CreateTable\n",
    "\n",
    "engine = sa.create_engine('redshift+psycopg2://user1@cluster1.cawq5wigr333.us-east-1.redshift.amazonaws.com:5439/stackdb1')\n",
    "metadata = sa.MetaData()\n",
    "\n",
    "questions = sa.Table(\n",
    "    'questions',\n",
    "    metadata,\n",
    "    sa.Column('post_id', sa.Integer, primary_key=True),\n",
    "    sa.Column('post_type_id', sa.Integer),\n",
    "    sa.Column('body', sa.String(32)), \n",
    "    sa.Column('views', sa.Integer),\n",
    "    sa.Column('score', sa.Integer),\n",
    "    sa.Column('fav_count', sa.Integer), \n",
    "    sa.Column('parent_id', sa.Integer),\n",
    "    sa.Column('owner_id', sa.Integer),\n",
    "    sa.Column('answer_count', sa.Integer), \n",
    "    sa.Column('comment_count', sa.Integer),)\n",
    "\n",
    "print(CreateTable(questions).compile(engine))\n",
    "\n",
    "from sqlalchemy_redshift.commands import CopyCommand\n",
    "\n",
    "CopyCommand(to=questions,\n",
    "           data_location='s3://stackexchangedatatest/load/df_q.csv',\n",
    "           access_key_id = access_key,\n",
    "           secret_access_key = access_secret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE answers (\n",
      "\tpost_id INTEGER NOT NULL, \n",
      "\tpost_type_id INTEGER, \n",
      "\tbody VARCHAR(32), \n",
      "\tviews INTEGER, \n",
      "\tscore INTEGER, \n",
      "\tfav_count INTEGER, \n",
      "\tparent_id INTEGER, \n",
      "\towner_id INTEGER, \n",
      "\tanswer_count INTEGER, \n",
      "\tcomment_count INTEGER, \n",
      "\tPRIMARY KEY (post_id)\n",
      ")\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sqlalchemy_redshift.commands.CopyCommand object at 0x000002554B928978>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = sa.Table(\n",
    "    'answers',\n",
    "    metadata,\n",
    "    sa.Column('post_id', sa.Integer, primary_key=True),\n",
    "    sa.Column('post_type_id', sa.Integer),\n",
    "    sa.Column('body', sa.String(32)), \n",
    "    sa.Column('views', sa.Integer),\n",
    "    sa.Column('score', sa.Integer),\n",
    "    sa.Column('fav_count', sa.Integer), \n",
    "    sa.Column('parent_id', sa.Integer),\n",
    "    sa.Column('owner_id', sa.Integer),\n",
    "    sa.Column('answer_count', sa.Integer), \n",
    "    sa.Column('comment_count', sa.Integer),)\n",
    "\n",
    "print(CreateTable(answers).compile(engine))\n",
    "\n",
    "from sqlalchemy_redshift.commands import CopyCommand\n",
    "\n",
    "CopyCommand(to=answers,\n",
    "           data_location='s3://stackexchangedatatest/load/df_a.csv',\n",
    "           access_key_id = access_key,\n",
    "           secret_access_key = access_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users_path = []\n",
    "\n",
    "for root, dirname, filenames in os.walk(path):\n",
    "    for filename in fnmatch.filter(filenames, 'Users.*'):\n",
    "        realname = os.path.join(root, filename)\n",
    "        users_path.append(realname)\n",
    "\n",
    "users_category_parsed = []\n",
    "for i in users_path:\n",
    "    users_category_parsed.append(et.parse(i).getroot().findall('row'))\n",
    "\n",
    "for j in users_category_parsed:\n",
    "    col_id = pd.Series([row.get('Id') for row in j]).rename('user_id')\n",
    "    col_rep = pd.Series([row.get('Reputation') for row in j]).rename('user_rep')\n",
    "    col_name = pd.Series([row.get('DisplayName') for row in j]).rename('display_name')\n",
    "    col_views =pd.Series([row.get('Views') for row in j]).rename('view_count')\n",
    "    col_upvotes =pd.Series([row.get('UpVotes') for row in j]).rename('upvotes')\n",
    "    col_downvotes = pd.Series([row.get('DownVotes') for row in j]).rename('downvotes')\n",
    "\n",
    "df_users = pd.concat([col_id, col_rep, col_name, col_views, col_upvotes, col_downvotes], join='outer', axis=1)\n",
    "\n",
    "\n",
    "users_stop_list= []\n",
    "users_stop_list2= []\n",
    "users_stop_list3= []\n",
    "users_final = []\n",
    "users_combined = []\n",
    "users_id_count_list = []\n",
    "\n",
    "for l, m in enumerate(users_id_count_list):\n",
    "    if m == '-1':\n",
    "        users_stop_list.append(l)\n",
    "\n",
    "        index_list = df_users.index.tolist()\n",
    "\n",
    "users_stop_list.append(index_list[-1] + 1)\n",
    "\n",
    "users_stop_list2.append([y - x for x, y in zip(users_stop_list, users_stop_list[1:])])\n",
    "\n",
    "for m in users_stop_list2:\n",
    "    for o in m:\n",
    "        users_stop_list3.append(o)\n",
    "\n",
    "for p, q in zip(categories, users_stop_list3):\n",
    "    users_final += [p for _ in range(q)]\n",
    "\n",
    "for r, s in zip(users_final, users_id_count_list):\n",
    "    users_combined += [r + '_' + str(s)]\n",
    "\n",
    "#df_users['category'] = pd.Series(users_combined).rename('category')  \n",
    "\n",
    "#df_users.to_sql(name='all_users', con=engine)\n",
    "\n",
    "df_users.to_csv('df_users.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "Table 'users' is already defined for this MetaData instance.  Specify 'extend_existing=True' to redefine options and columns on an existing Table object.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-56f15cd4be31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0msa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'view_count'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInteger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0msa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'upvotes'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInteger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     sa.Column('downvotes', sa.Integer),)\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCreateTable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sqlalchemy\\sql\\schema.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, *args, **kw)\u001b[0m\n\u001b[0;32m    396\u001b[0m                     \u001b[1;34m\"to redefine \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m                     \u001b[1;34m\"options and columns on an \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m                     \"existing Table object.\" % key)\n\u001b[0m\u001b[0;32m    399\u001b[0m             \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextend_existing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: Table 'users' is already defined for this MetaData instance.  Specify 'extend_existing=True' to redefine options and columns on an existing Table object."
     ]
    }
   ],
   "source": [
    "file_name_users = open('df_users.csv', 'rb')\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                    aws_access_key_id=access_key,\n",
    "                    aws_secret_access_key=access_secret,\n",
    "                    region_name='us-east-1')\n",
    "s3.Bucket(bucket_name).put_object(Key='df_users.csv', Body=file_name_users)\n",
    "\n",
    "users = sa.Table(\n",
    "    'users',\n",
    "    metadata,\n",
    "    sa.Column('user_id', sa.Integer, primary_key=True),\n",
    "    sa.Column('user_rep', sa.Integer),\n",
    "    sa.Column('display_name', sa.String(32)), \n",
    "    sa.Column('view_count', sa.Integer),\n",
    "    sa.Column('upvotes', sa.Integer),\n",
    "    sa.Column('downvotes', sa.Integer),)\n",
    "\n",
    "print(CreateTable(users).compile(engine))\n",
    "\n",
    "from sqlalchemy_redshift.commands import CopyCommand\n",
    "\n",
    "CopyCommand(to=users,\n",
    "           data_location='s3://stackexchangedatatest/load/df_users.csv',\n",
    "           access_key_id = access_key,\n",
    "           secret_access_key = access_secret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
