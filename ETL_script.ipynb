{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lxml import etree as et\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import fnmatch\n",
    "import itertools\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "path = ('stackexchange1')\n",
    "\n",
    "folders = os.listdir(path)\n",
    "\n",
    "\"\"\"\n",
    "def rename_files(self, path):\n",
    "    removal = '.stackexchange.com'\n",
    "    for folder in folders:  \n",
    "        os.rename(os.path.join(path, folder), os.path.join(path, folder.replace(removal, ' ')))\n",
    "\"\"\"\n",
    "\n",
    "categories = []\n",
    "for a in folders:\n",
    "    categories.append(str(a))\n",
    "\n",
    "def striphtml(data):\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub('', data)\n",
    "\n",
    "remover = lambda x: BeautifulSoup(x, 'lxml').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mingt\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\mingt\\AppData\\Local\\Continuum\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "posts_path = []\n",
    "for root, dirname, filenames in os.walk(path):\n",
    "    for filename in fnmatch.filter(filenames, 'Posts.*'):\n",
    "        realname = os.path.join(root, filename)\n",
    "        posts_path.append(realname)\n",
    "\n",
    "posts_category_parsed = []  \n",
    "for i in posts_path:\n",
    "    posts_category_parsed.append(et.parse(i).getroot().findall('row'))\n",
    "    \n",
    "for j in posts_category_parsed:\n",
    "    col_id = pd.Series([row.get('Id') for row in j]).rename('post_id')\n",
    "    #col_type = pd.Series([row.get('Type') for row in j]).rename('post_type')\n",
    "    col_post_type = pd.Series([row.get('PostTypeId') for row in j]).rename('post_type_id')\n",
    "\n",
    "    col_body = pd.Series([row.get('Body').encode('utf8') for row in j]).rename('body').apply(remover)\n",
    "    col_views = pd.Series([row.get('ViewCount') for row in j]).rename('views')\n",
    "    col_score = pd.Series([row.get('Score') for row in j]).rename('score')\n",
    "    col_fav = pd.Series([row.get('FavoriteCount') for row in j]).rename('fav_count')\n",
    "    \n",
    "    col_parentid = pd.Series([row.get('ParentId') for row in j]).rename('parent_id')\n",
    "    col_ownerid = pd.Series([row.get('OwnerUserId') for row in j]).rename('owner_id')\n",
    "    col_answer = pd.Series([row.get('AnswerCount') for row in j]).rename('answer_count')\n",
    "    col_comment = pd.Series([row.get('CommentCount') for row in j]).rename('comment_count')\n",
    "\n",
    "df_posts = pd.concat([col_id, col_post_type, col_body, col_views, col_score, col_fav, col_parentid, col_ownerid,\n",
    "                                col_answer, col_comment], join='outer', axis=1)\n",
    "\n",
    "posts_stop_list= []\n",
    "posts_stop_list2= []\n",
    "posts_stop_list3= []\n",
    "posts_final = []\n",
    "posts_combined = []\n",
    "posts_id_count_list = []\n",
    "\n",
    "for j in posts_category_parsed:\n",
    "    for row in j:\n",
    "       posts_id_count_list.append(row.get('Id'))\n",
    "\n",
    "for l, m in enumerate(col_post_type):\n",
    "    if m == '1':\n",
    "        posts_stop_list.append(l)\n",
    "\n",
    "index_list = df_posts.index.tolist()\n",
    "\n",
    "posts_stop_list.append(index_list[-1] + 1)  \n",
    "\n",
    "posts_stop_list2.append([y - x for x, y in zip(posts_stop_list, \n",
    "                                               posts_stop_list[1:])])\n",
    "\n",
    "for m in posts_stop_list2:\n",
    "    for o in m:\n",
    "        posts_stop_list3.append(o)\n",
    "\n",
    "for p, q in zip(categories, posts_stop_list3):\n",
    "        posts_final += [p for _ in range(q)]\n",
    "        \n",
    "for r, s in zip(posts_final, posts_id_count_list):\n",
    "    posts_combined += [r + '_' + str(s)]\n",
    "\n",
    "#df_posts['category'] = pd.Series(posts_combined).rename('category')  \n",
    "\n",
    "df_q = df_posts.groupby(['post_type_id']).get_group('1')\n",
    "df_a = df_posts.groupby(['post_type_id']).get_group('2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "access_key = keys['Access key ID'][0]\n",
    "access_secret = keys['Secret access key'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_q.to_csv('df_q.csv', index = False)\n",
    "df_a.to_csv('df_a.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s3.Object(bucket_name='stackexchangedatatest', key='df_q.csv')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "keys = pd.read_csv('keys.csv')\n",
    "access_key = keys['Access key ID'][0]\n",
    "access_secret = keys['Secret access key'][0]\n",
    "\n",
    "bucket_name = 'stackexchangedatatest'\n",
    "file_name_a = open('df_a.csv', 'rb')\n",
    "file_name_q = open('df_q.csv', 'rb')\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                    aws_access_key_id=access_key,\n",
    "                    aws_secret_access_key=access_secret,\n",
    "                    region_name='us-east-2')\n",
    "s3.Bucket(bucket_name).put_object(Key='df_a.csv', Body=file_name_a)\n",
    "s3.Bucket(bucket_name).put_object(Key='df_q.csv', Body=file_name_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_type_id</th>\n",
       "      <th>body</th>\n",
       "      <th>views</th>\n",
       "      <th>score</th>\n",
       "      <th>fav_count</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>owner_id</th>\n",
       "      <th>answer_count</th>\n",
       "      <th>comment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I keep losing pressure in my tires, and among ...</td>\n",
       "      <td>49009</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Are there adjustments that can be made instead...</td>\n",
       "      <td>42230</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>From what point to where do I start measuring?...</td>\n",
       "      <td>16226</td>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>I need to mail a bike from Portland, Oregon to...</td>\n",
       "      <td>4922</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>I have a single speed bicycle that has some sl...</td>\n",
       "      <td>18158</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id post_type_id                                               body  \\\n",
       "0       1            1  I keep losing pressure in my tires, and among ...   \n",
       "1       2            1  Are there adjustments that can be made instead...   \n",
       "2       4            1  From what point to where do I start measuring?...   \n",
       "3       5            1  I need to mail a bike from Portland, Oregon to...   \n",
       "4       6            1  I have a single speed bicycle that has some sl...   \n",
       "\n",
       "   views score fav_count parent_id owner_id answer_count comment_count  \n",
       "0  49009    40         4      None        7           11             0  \n",
       "1  42230    13         1      None       13            5             2  \n",
       "2  16226    13      None      None       10            3             2  \n",
       "3   4922    28         6      None       15            7             2  \n",
       "4  18158    21         2      None       17            5             2  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_q.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE questions (\n",
      "\tpost_id INTEGER NOT NULL, \n",
      "\tpost_type_id INTEGER, \n",
      "\t\"body text\" VARCHAR(32), \n",
      "\t\"views integer\" INTEGER, \n",
      "\t\"score integer\" INTEGER, \n",
      "\t\"fav_count integer\" INTEGER, \n",
      "\t\"parent_id integer\" INTEGER, \n",
      "\t\"owner_id integer\" INTEGER, \n",
      "\t\"answer_count integer\" INTEGER, \n",
      "\t\"comment_count integer\" INTEGER, \n",
      "\tPRIMARY KEY (post_id)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy.schema import CreateTable\n",
    "\n",
    "engine = sa.create_engine('redshift+psycopg2://user1@cluster1.cawq5wigr333.us-east-1.redshift.amazonaws.com:5439/stackdb1')\n",
    "metadata = sa.MetaData()\n",
    "\n",
    "questions = sa.Table(\n",
    "    'questions',\n",
    "    metadata,\n",
    "    sa.Column('post_id', sa.Integer, primary_key=True),\n",
    "    sa.Column('post_type_id', sa.Integer),\n",
    "    sa.Column('body text', sa.String(32)), \n",
    "    sa.Column('views integer', sa.Integer),\n",
    "    sa.Column('score integer', sa.Integer),\n",
    "    sa.Column('fav_count integer', sa.Integer), \n",
    "    sa.Column('parent_id integer', sa.Integer),\n",
    "    sa.Column('owner_id integer', sa.Integer),\n",
    "    sa.Column('answer_count integer', sa.Integer), \n",
    "    sa.Column('comment_count integer', sa.Integer),)\n",
    "\n",
    "print(CreateTable(questions).compile(engine))\n",
    "#engine.execute(\"COPY df_q.csv FROM 's3://stackexchangedatatest/load/df_a.csv' WITH CREDENTIALS aws_access_key_id=AKIAIDB2AFAZDA4YFX4A;aws_secret_access_key=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';\").execution_options(autocommit=True)\n",
    "\n",
    "#engine.execute(\"COPY table FROM 's3://stackexchangedatatest/load/df_a.csv' WITH CREDENTIALS aws_access_key_id=AKIAIDB2AFAZDA4YFX4A;aws_secret_access_key=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';\" csv;).execution_options(autocommit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy_redshift.commands.CopyCommand object at 0x000002554B9385F8>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy_redshift.commands import CopyCommand\n",
    "\n",
    "CopyCommand(to=questions,\n",
    "           data_location='s3://stackexchangedatatest/load/df_q.csv',\n",
    "           access_key_id = access_key,\n",
    "           secret_access_key = access_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "database flavor mysql is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-6b69faa9e1f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#engine2 = create_engine('mysql+mysqlconnector://ssh mingting@104.40.74.232/VotingBehaviorStudy')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#engine3 = create_engine('mysql+pymysql://jmt7080:Fall2015!@se-db1.cdyyfioivjtf.us-east-2.rds.amazonaws.com:3306/db1')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf_q\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'se_questions'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflavor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mysql'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdf_a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'se_answers'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflavor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mysql'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, name, con, flavor, schema, if_exists, index, index_label, chunksize, dtype)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         sql.to_sql(self, name, con, flavor=flavor, schema=schema,\n\u001b[0;32m   1361\u001b[0m                    \u001b[0mif_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mif_exists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1362\u001b[1;33m                    chunksize=chunksize, dtype=dtype)\n\u001b[0m\u001b[0;32m   1363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'infer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, flavor, schema, if_exists, index, index_label, chunksize, dtype)\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'{0}' is not valid for if_exists\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mif_exists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m     \u001b[0mpandas_sql\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandasSQL_builder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflavor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflavor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mpandasSQL_builder\u001b[1;34m(con, flavor, schema, meta, is_cursor)\u001b[0m\n\u001b[0;32m    525\u001b[0m     \u001b[0mprovided\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m     \"\"\"\n\u001b[1;32m--> 527\u001b[1;33m     \u001b[0m_validate_flavor_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflavor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;31m# When support for DBAPI connections is removed,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36m_validate_flavor_parameter\u001b[1;34m(flavor)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             raise ValueError(\"database flavor {flavor} is not \"\n\u001b[1;32m---> 59\u001b[1;33m                              \"supported\".format(flavor=flavor))\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: database flavor mysql is not supported"
     ]
    }
   ],
   "source": [
    "#engine = create_engine('mysql+pymysql://Ming:asdfg@localhost:3306/ist343')\n",
    "#engine2 = create_engine('mysql+mysqlconnector://ssh mingting@104.40.74.232/VotingBehaviorStudy')\n",
    "#engine3 = create_engine('mysql+pymysql://jmt7080:Fall2015!@se-db1.cdyyfioivjtf.us-east-2.rds.amazonaws.com:3306/db1')\n",
    "df_q.to_sql(name='se_questions', con=engine, flavor='mysql', index=False)\n",
    "df_a.to_sql(name='se_answers', con=engine, flavor='mysql', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for root, dirname, filenames in os.walk(path):\n",
    "    for filename in fnmatch.filter(filenames, 'Users.*'):\n",
    "        realname = os.path.join(root, filename)\n",
    "        users_path.append(realname)\n",
    "    for i in users_path:\n",
    "        users_category_parsed.append(et.parse(i).getroot().findall('row'))\n",
    "    for j in users_category_parsed:\n",
    "           col_id = pd.Series([row.get('Id') for row in j]).rename('user_id')\n",
    "           col_rep = pd.Series([row.get('Reputation') for row in j]).rename('user_rep')\n",
    "           col_name = pd.Series([row.get('DisplayName') for row in j]).encode('utf8').rename('display_name')\n",
    "           col_views =pd.Series([row.get('Views') for row in j]).rename('view_count')\n",
    "           col_upvotes =pd.Series([row.get('UpVotes') for row in j]).rename('upvotes')\n",
    "           col_downvotes = pd.Series([row.get('DownVotes') for row in j]).rename('downvotes')\n",
    "\n",
    "df_users = pd.concat([col_id, col_rep, col_name, col_views, col_upvotes, col_downvotes], join='outer', axis=1)\n",
    "\n",
    "users_stop_list= []\n",
    "users_stop_list2= []\n",
    "users_stop_list3= []\n",
    "users_final = []\n",
    "users_combined = []\n",
    "users_id_count_list = []\n",
    "\n",
    "for l, m in enumerate(users_id_count_list):\n",
    "    if m == '-1':\n",
    "        users_stop_list.append(l)\n",
    "\n",
    "        index_list = df_users.index.tolist()\n",
    "\n",
    "users_stop_list.append(index_list[-1] + 1)\n",
    "\n",
    "users_stop_list2.append([y - x for x, y in zip(users_stop_list, users_stop_list[1:])])\n",
    "\n",
    "for m in users_stop_list2:\n",
    "    for o in m:\n",
    "        users_stop_list3.append(o)\n",
    "\n",
    "for p, q in zip(categories, users_stop_list3):\n",
    "    users_final += [p for _ in range(q)]\n",
    "\n",
    "for r, s in zip(users_final, users_id_count_list):\n",
    "    users_combined += [r + '_' + str(s)]\n",
    "\n",
    "category = pd.Series(users_combined)\n",
    "df_users['category'] = users_combined\n",
    "\n",
    "df_users.to_sql(name='all_users', con=engine)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
